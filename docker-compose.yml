services:
  deepseek:
    image: byron758/woohengine-deepseek:1.3
    container_name: deepseek-container
    restart: unless-stopped
    ports:
      - "8088:80"        # Apache Web Server
      - "11434:11434"    # Ollama API
    environment:
      - DEBIAN_FRONTEND=noninteractive
    volumes:
      - ollama_models:/root/.ollama/models  # Persist model data
    networks:
      - deepseek_network

networks:
  deepseek_network:
    driver: bridge

volumes:
  ollama_models:  # Named volume for model persistence